{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms,models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: tetiana-trachuk-kn-2021 (tetiana-trachuk-kn-2021-) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Diploma\\Diploma\\wandb\\run-20250223_180422-tkgvhvb6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tetiana-trachuk-kn-2021-/mobilenet-skin-disease-classification/runs/tkgvhvb6' target=\"_blank\">hearty-lion-2</a></strong> to <a href='https://wandb.ai/tetiana-trachuk-kn-2021-/mobilenet-skin-disease-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tetiana-trachuk-kn-2021-/mobilenet-skin-disease-classification' target=\"_blank\">https://wandb.ai/tetiana-trachuk-kn-2021-/mobilenet-skin-disease-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tetiana-trachuk-kn-2021-/mobilenet-skin-disease-classification/runs/tkgvhvb6' target=\"_blank\">https://wandb.ai/tetiana-trachuk-kn-2021-/mobilenet-skin-disease-classification/runs/tkgvhvb6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tetiana-trachuk-kn-2021-/mobilenet-skin-disease-classification/runs/tkgvhvb6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1953664e060>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 7\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS_NUM = 15\n",
    "\n",
    "wandb.init(\n",
    "    project=\"mobilenet-skin-disease-classification\",\n",
    "    config={\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"num_classes\": NUM_CLASSES,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"epochs\": EPOCHS_NUM,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True  # Optimizes GPU performance\n",
    "\n",
    "# Data Transforms\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = ImageFolder(root='C:/Diploma/classification_dataset', transform=augmentation_transforms)\n",
    "train_size = int(0.85 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "test_dataset.dataset.transform = test_transforms\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Diploma\\Diploma\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Diploma\\Diploma\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "# Define Optimizer & Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.9744, Acc: 0.6036, Prec: 0.5614, Recall: 0.5570, F1: 0.5581\n",
      "Epoch [2/15], Loss: 0.7834, Acc: 0.6965, Prec: 0.6625, Recall: 0.6590, F1: 0.6603\n",
      "Epoch [3/15], Loss: 0.6723, Acc: 0.7456, Prec: 0.7143, Recall: 0.7127, F1: 0.7132\n",
      "Epoch [4/15], Loss: 0.6049, Acc: 0.7672, Prec: 0.7373, Recall: 0.7355, F1: 0.7362\n",
      "Epoch [5/15], Loss: 0.5408, Acc: 0.7960, Prec: 0.7687, Recall: 0.7672, F1: 0.7678\n",
      "Epoch [6/15], Loss: 0.4851, Acc: 0.8209, Prec: 0.7975, Recall: 0.7966, F1: 0.7969\n",
      "Epoch [7/15], Loss: 0.4396, Acc: 0.8359, Prec: 0.8129, Recall: 0.8128, F1: 0.8127\n",
      "Epoch [8/15], Loss: 0.3894, Acc: 0.8562, Prec: 0.8360, Recall: 0.8359, F1: 0.8357\n",
      "Epoch [9/15], Loss: 0.3453, Acc: 0.8775, Prec: 0.8577, Recall: 0.8574, F1: 0.8574\n",
      "Epoch [10/15], Loss: 0.3142, Acc: 0.8859, Prec: 0.8688, Recall: 0.8697, F1: 0.8691\n",
      "Epoch [11/15], Loss: 0.3179, Acc: 0.8809, Prec: 0.8643, Recall: 0.8636, F1: 0.8639\n",
      "Epoch [12/15], Loss: 0.2551, Acc: 0.9080, Prec: 0.8947, Recall: 0.8952, F1: 0.8949\n",
      "Epoch [13/15], Loss: 0.2376, Acc: 0.9174, Prec: 0.9053, Recall: 0.9054, F1: 0.9053\n",
      "Epoch [14/15], Loss: 0.2592, Acc: 0.9062, Prec: 0.8950, Recall: 0.8953, F1: 0.8951\n",
      "Epoch [15/15], Loss: 0.2882, Acc: 0.8960, Prec: 0.8830, Recall: 0.8824, F1: 0.8827\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS_NUM):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS_NUM}], Loss: {running_loss/len(train_loader):.4f}, Acc: {acc:.4f}, Prec: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch+1, \n",
    "        \"loss\": running_loss/len(train_loader),  \n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.37%\n"
     ]
    }
   ],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the class with highest probability\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    # wandb.log({\"test_accuracy\": accuracy})\n",
    "\n",
    "# Run Evaluation Immediately After Training\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.save(model.state_dict(), \"mobilenet_skin_disease_model.pth\")\n",
    "print(\"Model training complete and saved.\")\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
